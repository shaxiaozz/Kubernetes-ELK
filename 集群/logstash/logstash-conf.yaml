apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-conf
  namespace: monitoring
  labels:
    name: logstash
    app: elk
data:
  nginx.conf: |
    # 设置logstash的输入源从kafka的topic中获取
    input {
      kafka {
        bootstrap_servers => "kafka-0-0.kafka-svc:9092,kafka-1-0.kafka-svc:9092,kafka-2-0.kafka-svc:9092"
        topics => "nginx_access_logs"
        codec => "json"
        consumer_threads => 5
        decorate_events => true
      }
    }
    # 根据字段值判断是否需要做处理
    filter {
       if [fields][log_topics] == "nginx_access_logs" {
          geoip {
            source => "clientip"
            target => "geoip"
            database => "/usr/share/logstash/vendor/bundle/jruby/2.5.0/gems/logstash-filter-geoip-6.0.3-java/vendor/GeoLite2-City.mmdb"
            add_field => [ "[geoip][coordinates]", "%{[geoip][longitude]}" ]
            add_field => [ "[geoip][coordinates]", "%{[geoip][latitude]}"  ]
          }
       if "_geoip_lookup_failure" in [tags] { drop { } }
       mutate {
         convert => ["[geoip][coordinates]", "float"]
         remove_field => "timestamp"
       }
       }
    }
    # 输出到ES进行存储
    output {
      if [fields][log_topics] == "nginx_access_logs" {
        elasticsearch {
            hosts => ["elasticsearch-0-0.elasticsearch-svc:9200","elasticsearch-1-0.elasticsearch-svc:9200","elasticsearch-2-0.elasticsearch-svc:9200"]
            index => "nginx_accesslog-%{+YYYY.MM.dd}"
            user => "elastic"
            password => "qNB1uZx3xrkpAcFO1PZl"
        }
      }
    }
